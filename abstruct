abstruct Crawler
func : &setFetchJobs()//设置爬虫任务
func : getFetchJobs()//获取所有任务
func : handlePage()//对每个页面的操作
func : run();//运行爬虫
para : 
	page_class_name //页面类的名字
	page_conf //页面的配置




abstruct Page
func : getConf() //
func : getUrl()  // 获取页面的url
func : init()	//初始化
func : read() 	 //根据url读取页面html并保存为字符串
func : setConf() //
func : setUrl()  //设置url
func : getHyperLinks()	//获取所有a链接

abstruct Dom
func : getElementById()
func : getElementsByTagName()
func : loadHTML()
func : sel()


$crawler = new xx()
生成爬虫对象

$crawler->setFetchJobs( $arr );
	start_page
	max_depth
	max_pages
	link_rules
向爬虫对象中添加任务队列

$crawler->run();
运行爬虫
构建page对象
对page对象进行配置
遍历任务数组
	如果arrJobs[pop]非空，就一直循环（每循环一次深度+1）
		清空Push数组
		遍历arrJobs中pop中的url
			读取页面、页面内的url（并将url保存到arrHash中）
			对页面内的url进行操作(匹配reg，保存到arrPush中)
			执行handlePage()
		交换Pop与Push（交换之后Pop中是下一次while循环中需要爬取的url）


